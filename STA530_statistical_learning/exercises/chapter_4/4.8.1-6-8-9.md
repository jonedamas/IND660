# 4.8.1

Using a little bit of algebra, prove that (4.2) is equivalent to (4.3). In other words, the logistic function representation and logit representation for the logistic regression model are equivalent.

$$
p(X)=\frac{e^{\beta_0+\beta_1X}}{1+e^{\beta_0+\beta_1X}} 
$$

***

$$
\[
p(X)(1+e^{\beta_0+\beta_1X})=e^{\beta_0+\beta_1X}
\]
p(X)+p(X)e^{\beta_0+\beta_1X}=e^{\beta_0+\beta_1X} \\[1em]
p(X)=e^{\beta_0+\beta_1X}-p(X)e^{\beta_0+\beta_1X} \\[1em]
p(X)=e^{\beta_0+\beta_1X}(1-p(X)) \\[1em]
\frac{p(X)}{1-p(X)}=e^{\beta_0+\beta_1X}
$$

# 4.8.6

Suppose we collect data for a group of students in a statistics class
with variables $X_1$ = hours studied, $X_2$ = undergrad GPA, and $Y$ =
receive an A. We fit a logistic regression and produce estimated
coefficient, $β^0 = −6$, $β^1 = 0.05$, $β^2 = 1$.

$$
p(X_1, X_2)=\frac{e^{-6+0.05X_1+X_2}}{1+e^{-6+0.05X_1+X_2}}
$$

***

### a.)
Estimate the probability that a student who studies for 40 h and
has an undergrad GPA of 3.5 gets an A in the class.
$$
p(40, 3.5)=\frac{e^{-6+0.05(40)+3.5}}{1+e^{-6+0.05(40)+3.5}}=0.378\\[1em]
$$


### b.)
How many hours would the student in part (a) need to study to have a 50 % chance of getting an A in the class?

Rearranging the equation for $p(X_1, X_2)$ to solve for $X_1$ we get:
$$
X_1=\frac{1}{\beta_1}\bigg(\ln\bigg(\frac{p(X_1, X_2)}{1-p(X_1, X_2)}\bigg)-\beta_0-\beta_2X_2\bigg) \\[1em]
$$

Solve for $X_1$:
$$
X_1=\frac{1}{0.05}\bigg(\ln\bigg(\frac{0.50}{1-0.50}\bigg)+6-1\cdot 3.5\bigg)=50 \\[1em]
$$

The student would need to study 50 hours to have a 50% chance of getting an A in the class.

# 4.8.8

Suppose that we take a data set, divide it into equally-sized training and test sets, and then try out two different classification procedures. First we use logistic regression and get an error rate of 20 % on the training data and 30 % on the test data. Next we use 1-nearest neighbors (i.e. K = 1) and get an average error rate (averaged over both test and training data sets) of 18 %. Based on these results, which method should we prefer to use for classification of new observations?
Why?

***

We should prefer the 1-nearest neighbors method because it has a lower error rate on average. The logistic regression model is overfitting the training data and is not generalizing well to the test data.

# 4.8.9

This problem has to do with odds.

### a.)

On average, what fraction of people with an odds of 0.37 of defaulting on their credit card payment will in fact default?

***

$$
0.37=\frac{p(X)}{1-p(X)} \\[1em]
\Rightarrow p(X)=\frac{0.37}{1+0.37}=0.27
$$

0.27 of people with an odds of 0.37 of defaulting on their credit card payment will in fact default.

### b.)

Suppose that an individual has a 16 % chance of defaulting on her credit card payment. What are the odds that she will default?

$$
\frac{0.16}{1-0.16}=0.19 \\[1em]
$$

The odds that she will default are 0.19.
